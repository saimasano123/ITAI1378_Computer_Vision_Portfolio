Manually performing convolution operations was an enlightening experience that deepened my understanding of the core mechanics of Convolutional Neural Networks (CNNs). By manually applying filters (kernels) to an input matrix and calculating feature maps step-by-step, I learned how CNNs extract features like edges, textures, and patterns from images. This exercise reinforced the significance of kernel size, stride, and padding in determining the output dimensions and the level of detail captured.

One challenge was ensuring accuracy while computing the convolutions, as even small errors in calculations could lead to incorrect feature maps. To address this, I worked systematically, rechecking computations and visualizing the process to confirm correctness. This hands-on approach highlighted the role of each component in the convolution operation and how parameter choices affect the feature extraction process.

This lab highlighted the efficiency of Convolutional Neural Networks (CNNs) in image classification tasks compared to traditional neural networks. Unlike traditional neural networks, which process flattened input data, CNNs maintain the spatial structure of images using convolutional and pooling layers. These layers extract hierarchical features, such as edges, textures, and complex patterns, making CNNs particularly suited for distinguishing visually similar objects like muffins and chihuahuas.